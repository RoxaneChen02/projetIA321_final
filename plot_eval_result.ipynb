{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot result from RL evaluation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = [\n",
    "    \"logs_ppo_cnn_rlzoo_hp/Iteration1/eval_log/evaluations.npz\",\n",
    "    \"logs_ppo_cnn_rlzoo_hp/Iteration2/eval_log/evaluations.npz\",\n",
    "    \"logs_ppo_cnn_rlzoo_hp/Iteration3/eval_log/evaluations.npz\",\n",
    "    \"logs_ppo_cnn_rlzoo_hp/Iteration4/eval_log/evaluations.npz\",\n",
    "    \"logs_ppo_cnn_rlzoo_hp/Iteration5/eval_log/evaluations.npz\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = np.load(path_to_files[0])\n",
    "data['results'].shape # (nombre de timesteps, nb d'evaluation par timesteps)\n",
    "data['results'].mean(axis=1)\n",
    "data['timesteps'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_full = []\n",
    "max_length = 0  # Initialize variable to store maximum length\n",
    "\n",
    "# Iterate over each file in path_to_files\n",
    "for file in path_to_files:\n",
    "    data = np.load(file)\n",
    "    eval_rewards = data['results'].mean(axis=1)\n",
    "    data_full.append(eval_rewards)\n",
    "    max_length = max(max_length, len(eval_rewards))  # Update max_length\n",
    "\n",
    "# Pad sequences to make them homogeneous\n",
    "padded_data_full = []\n",
    "for seq in data_full:\n",
    "    padded_seq = np.pad(seq, (0, max_length - len(seq)), mode='constant')\n",
    "    padded_data_full.append(padded_seq)\n",
    "\n",
    "# Convert padded_data_full into a NumPy array\n",
    "data_full_array = np.array(padded_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data_full_array.mean(axis = 0)\n",
    "std =  data_full_array.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Generate x-axis values based on the length of mean\n",
    "x_values = np.arange(len(mean))*1000\n",
    "\n",
    "# Plot mean\n",
    "plt.plot(x_values, mean)\n",
    "\n",
    "# Shade the area between mean plus std and mean minus std\n",
    "plt.fill_between(x_values, mean + std, mean - std, alpha=0.3)\n",
    "#plt.axhline(y=800, color='r', linestyle='--', label='Average manual policy reward')\n",
    "\n",
    "plt.axhline(y=-26.3893, color='b', linestyle='--', label='Average random policy reward')\n",
    "# Add labels and legend\n",
    "\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Rewards')\n",
    "plt.legend()\n",
    "plt.xlim(0, 90000)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
